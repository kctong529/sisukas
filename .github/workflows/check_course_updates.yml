name: Check Course Updates

on:
  workflow_dispatch:
  schedule:
    # Run daily at 6 AM UTC
    - cron: '0 6 * * *'
  push:
    branches:
      - dev

env:
  PYTHON_VERSION: '3.12'
  GCS_BUCKET: 'sisukas-core-test'

jobs:
  prepare_data:
    runs-on: ubuntu-latest
    permissions:
      contents: 'read'
      id-token: 'write'
    outputs:
      has_changes: ${{ steps.check_changes.outputs.has_changes }}
    steps:
      - name: Checkout main branch
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: pip install requests

      - name: Fetch current JSON
        run: |
          curl -fSL "https://storage.googleapis.com/${{ env.GCS_BUCKET }}/courses.json" -o courses.json || echo "No existing courses.json"

      - name: Fetch latest courses
        env:
          AALTO_USER_KEY: ${{ secrets.AALTO_USER_KEY }}
        run: python scripts/fetch_latest_courses.py

      - name: Transform latest fetch
        run: |
          python scripts/transform_courses.py latest_fetch.json latest.json

      - name: Check for changes
        id: check_changes
        run: |
          python scripts/report_course_changes.py
          echo "Exit code: $?"
        continue-on-error: true

      - name: Prepare artifacts
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          gzip -c latest.json > courses.json.gz
          python scripts/generate_hash.py latest.json courses.hash.json
          LATEST_LOG=$(ls -1t logs/course_changes_*.json | head -n 1)
          mkdir -p artifacts
          cp courses.json.gz artifacts/
          cp courses.hash.json artifacts/
          cp "$LATEST_LOG" artifacts/

      - name: Upload artifacts
        if: steps.check_changes.outputs.has_changes == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: courses-artifacts
          path: artifacts/

  upload_to_gcs:
    needs: prepare_data
    runs-on: ubuntu-latest
    if: needs.prepare_data.outputs.has_changes == 'true'
    permissions:
      id-token: 'write'
    steps:
      - name: Checkout main branch
        uses: actions/checkout@v4

      - id: auth
        uses: google-github-actions/auth@v3
        with:
          project_id: 'sisukas-fastapi'
          workload_identity_provider: 'projects/969370446235/locations/global/workloadIdentityPools/github/providers/my-repo'
          service_account: 'github-actions-deployer@sisukas-fastapi.iam.gserviceaccount.com'

      - name: Print active identity
        run: |
          gcloud auth list
          gcloud config list

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          name: courses-artifacts
          path: artifacts

      - name: Upload to GCS using gcloud (renamed to courses.json)
        env:
          BUCKET_NAME: ${{ env.GCS_BUCKET }}
        run: |
          gcloud storage cp \
            artifacts/courses.json.gz \
            gs://$BUCKET_NAME/courses.json \
            --content-type="application/json" \
            --content-encoding="gzip"

      - name: Upload hash file (no caching)
        env:
          BUCKET_NAME: ${{ env.GCS_BUCKET }}
        run: |
          gcloud storage cp \
            -h "Cache-Control:no-store, max-age=0" \
            artifacts/courses.hash.json \
            gs://$BUCKET_NAME/courses.hash.json

      - name: Upload log files
        uses: google-github-actions/upload-cloud-storage@v3
        with:
          path: artifacts
          glob: "course_changes_*.json"
          destination: sisukas-core-test/logs
          headers: |-
            content-type: 'application/json'